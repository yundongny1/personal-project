{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code I have written for the school of information sciences research, Responsible Use of Data, under Dr. Jana Diesner with supervision of Julian Chin.\n",
    "\n",
    "The main goal of this research was to identify and extract relevant information from data regulations, transform texts into easy-to-interpret “labels”, and increase researchers’ awareness, knowledge, and skills on responsible use of data.\n",
    "\n",
    "The task also involved co-authoring *Exploring the Ethical Considerations from Computational Linguistics Studies* in IC2S2 (8th International Conference on Computational Social Science).\n",
    "\n",
    "To extract relevant information from relevant data regulations, we found and converted more than 100 journals containig a section raising concern on data ethics, and mass converted the pdf files to txt files using the Action Wizard tool on Adobe Acrobat DC.\n",
    "\n",
    "The paragraphs were then extracted using the below code, and tokenized using simple tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first thing to do is read the file locating the txts` probably and find a way to read all the txt files\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "mypath = r\"C:\\Users\\Justin\\Documents\\rud\\naacl txts\"\n",
    "\n",
    "#function to turn text into paragraphs\n",
    "def txt2paragraph(filepath):\n",
    "    with open(filepath) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    paragraph = ''\n",
    "    for line in lines:\n",
    "        if line.isspace():  # is it an empty line?\n",
    "            if paragraph:\n",
    "                yield paragraph\n",
    "                paragraph = ''\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            paragraph += ' ' + line.strip()\n",
    "    yield paragraph\n",
    "\n",
    "\n",
    "#function to go through directory and apply function\n",
    "for filename in os.listdir(mypath):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        a = list(txt2paragraph(filename))\n",
    "        ethics = []\n",
    "        matches = [\"Ethic\", \"Ethical\", \"Ethics\", \"Broader\"]\n",
    "        for i in a:\n",
    "            #if \"Ethic\" in i:\n",
    "            if any(x in i for x in matches):\n",
    "                ethics.append(i)\n",
    "        textfile = open(filename, \"w\")\n",
    "        for element in ethics:\n",
    "            textfile.write(element + \"\\n\")\n",
    "        textfile.close()\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Total number of words is 8133',\n",
       " 'Average number of words per file is 173.04255319148936')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypath1 = r\"C:\\Users\\Justin\\Documents\\rud\\naacl ethic statements\"\n",
    "\n",
    "#helper function that counts number words in txt file\n",
    "def countwords(filepath):\n",
    "    file = open(filepath, encoding=\"utf8\")\n",
    "    data = file.read()\n",
    "    words = data.split()\n",
    "    return len(words)\n",
    "\n",
    "#function to count and sum number of words in folder\n",
    "\n",
    "def countwordsinfile(path):\n",
    "    #for each filename in the folder\n",
    "    a = []\n",
    "    for filename in os.listdir(path):\n",
    "        #appends count of each txt file to a list\n",
    "        a.append(countwords(path + \"\\\\\" + filename))\n",
    "        #return sum of the list\n",
    "    return(\"Total number of words is {}\".format(sum(a)),\n",
    "          \"Average number of words per file is {}\".format(sum(a) / len(a)))\n",
    "    \n",
    "countwordsinfile(mypath1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Total number of sentences is 407',\n",
       " 'Average number of sentences per file is 8.659574468085106')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "def countsentencesinfile(path):\n",
    "    holder = []\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        with open(mypath1 + \"\\\\\" + filename, encoding=\"utf8\") as f: \n",
    "            doc = nlp(f.read())\n",
    "        sentence_tokens = [[token.text for token in sent] for sent in doc.sents]\n",
    "        holder.append(len(sentence_tokens))\n",
    "    return(\"Total number of sentences is {}\".format(sum(holder)),\n",
    "          \"Average number of sentences per file is {}\".format(sum(holder) / len(holder)))\n",
    "        \n",
    "countsentencesinfile(mypath1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
